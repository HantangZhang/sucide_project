{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "# if using mac\n",
    "df = pd.read_excel('/Users/zhanghantang/PycharmProjects/sucide_project/BIOM40forUSC.xlsx')\n",
    "data = df[df['SI'].notnull()]\n",
    "y = data['SI']\n",
    "x = data.loc[:, 'GIMAP1Biom1552316_a_at':'CFIS']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\PHD\\\\sucide_project\\\\BIOM40forUSC.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/73/3f_t97jx5y7d14c8_np58h8m0000gn/T/ipykernel_56937/2421970234.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# windows\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'E:\\PHD\\sucide_project\\BIOM40forUSC.xlsx'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'SI'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotnull\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'SI'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'GIMAP1Biom1552316_a_at'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'CFIS'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001B[0m\n\u001B[1;32m    362\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         \u001B[0mshould_close\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0mio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m         raise ValueError(\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_or_buffer, engine, storage_options)\u001B[0m\n\u001B[1;32m   1189\u001B[0m                 \u001B[0mext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xls\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1190\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1191\u001B[0;31m                 ext = inspect_excel_format(\n\u001B[0m\u001B[1;32m   1192\u001B[0m                     \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1193\u001B[0m                 )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36minspect_excel_format\u001B[0;34m(content_or_path, storage_options)\u001B[0m\n\u001B[1;32m   1068\u001B[0m         \u001B[0mcontent_or_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontent_or_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1070\u001B[0;31m     with get_handle(\n\u001B[0m\u001B[1;32m   1071\u001B[0m         \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_text\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1072\u001B[0m     ) as handle:\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    709\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    710\u001B[0m             \u001B[0;31m# Binary mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 711\u001B[0;31m             \u001B[0mhandle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    712\u001B[0m         \u001B[0mhandles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'E:\\\\PHD\\\\sucide_project\\\\BIOM40forUSC.xlsx'"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "df = pd.read_excel('E:\\PHD\\sucide_project\\BIOM40forUSC.xlsx')\n",
    "data = df[df['SI'].notnull()]\n",
    "y = data['SI']\n",
    "x = data.loc[:, 'GIMAP1Biom1552316_a_at':'CFIS']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 151\n"
     ]
    }
   ],
   "source": [
    "# column 'CFI-S.PheneVisit' data type is string, i am not clear its internal meaning and how to convert to float data type\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = x.drop(labels='CFI-S.PheneVisit', axis=1)\n",
    "# drop these column directly\n",
    "x = data.loc[:, 'GIMAP1Biom1552316_a_at':'RAB3GAP2Biom240234_at']\n",
    "new_y = []\n",
    "for i in y:\n",
    "    if i == 0 or i ==1:\n",
    "        new_y.append(0)\n",
    "    else:\n",
    "        new_y.append(1)\n",
    "y = np.array(new_y)\n",
    "X = StandardScaler().fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size=0.2, random_state=10)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "# todo unified randome state\n",
    "unified_random_state = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "-------------------------\n",
    "the content below is about logistic regression content\n",
    "-------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.24390244 0.11764706 0.35897436 0.25531915 0.18181818]\n",
      "Mean Score:  0.23153223751532614\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nScores:  [0.24390244 0.11764706 0.35897436 0.25531915 0.18181818]\\nMean Score:  0.23153223751532614\\n'"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# test parameter individually\n",
    "\n",
    "# Create the K-Fold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define your model\n",
    "model = LR(solver='saga', penalty='elasticnet', C=100, max_iter=3000, l1_ratio=0.5)\n",
    "\n",
    "# Use the cross_val_score function to obtain the scores for each fold\n",
    "scores = cross_val_score(model, X, new_y, cv=kf, scoring='f1')\n",
    "\n",
    "\n",
    "# Print the scores for each fold and the mean score\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Mean Score: \", scores.mean())\n",
    "\n",
    "'''\n",
    "Scores:  [0.24390244 0.11764706 0.35897436 0.25531915 0.18181818]\n",
    "Mean Score:  0.23153223751532614\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best penalty:  l1\n",
      "Best C:  100\n",
      "Best score:  0.19299478970021897\n"
     ]
    }
   ],
   "source": [
    "# tune parameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LR(solver='saga')\n",
    "# 不同的solver可能只支持不同的有限的penalty\n",
    "param_grid = {'penalty':['l1', 'l2'], 'C':[0.1, 1, 10, 100], 'max_iter':[3000, 3500]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', return_train_score=True)\n",
    "grid_search.fit(X, new_y)\n",
    "print(\"Best penalty: \", grid_search.best_params_['penalty'])\n",
    "print(\"Best C: \", grid_search.best_params_['C'])\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "'''\n",
    "Best penalty:  l1\n",
    "Best C:  100\n",
    "Best score:  0.19299478970021897\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with L1 penalty: accuracy:0.7831325301204819 precision:0.4074074074074074 recall:0.22448979591836735 f1:0.2894736842105263 roc_auc:0.5722448979591838\n"
     ]
    }
   ],
   "source": [
    "best_lr_model = LR(C=100, penalty='l1', solver='saga', max_iter=3000)\n",
    "best_lr_model.fit(X_train, y_train)\n",
    "y_pred = best_lr_model.predict(X_test)\n",
    "print(\"Score with L1 penalty: accuracy:{} precision:{} recall:{} f1:{} roc_auc:{}\".format(accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)))\n",
    "'''\n",
    "Score with L1 penalty: accuracy:0.7831325301204819 precision:0.4074074074074074 recall:0.22448979591836735 f1:0.2894736842105263 roc_auc:0.5722448979591838\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "-------------------------\n",
    "the content below is about SVM\n",
    "-------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: accuracy is [0.7615894  0.74834437 0.74172185 0.7615894  0.58      ], mean accuary is 0.7186490066225166\n",
      "Scores: precision is [0.29411765 0.15384615 0.33333333 0.33333333 0.26027397], mean accuary is 0.27498088803487675\n",
      "Scores: recall is [0.17241379 0.06896552 0.34482759 0.28571429 0.67857143], mean accuary is 0.31009852216748773\n",
      "Scores: f1 is [0.2173913  0.0952381  0.33898305 0.30769231 0.37623762], mean accuary is 0.26710847637761254\n",
      "Scores: roc_auc is [0.56783493 0.60655738 0.65008479 0.71544715 0.69818501], mean accuary is 0.6476218543781174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = SVC(C=100, kernel='rbf', max_iter=10000)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "scores = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "# y_pred = model.predict(X)\n",
    "print(\"Scores: accuracy is {}, mean accuary is {}\".format(scores['test_accuracy'], scores['test_accuracy'].mean()))\n",
    "print(\"Scores: precision is {}, mean accuary is {}\".format(scores['test_precision'], scores['test_precision'].mean()))\n",
    "print(\"Scores: recall is {}, mean accuary is {}\".format(scores['test_recall'], scores['test_recall'].mean()))\n",
    "print(\"Scores: f1 is {}, mean accuary is {}\".format(scores['test_f1'], scores['test_f1'].mean()))\n",
    "print(\"Scores: roc_auc is {}, mean accuary is {}\".format(scores['test_roc_auc'], scores['test_roc_auc'].mean()))\n",
    "\n",
    "'''\n",
    "Scores: accuracy is [0.7615894  0.74834437 0.74172185 0.7615894  0.58      ], mean accuary is 0.7186490066225166\n",
    "Scores: precision is [0.29411765 0.15384615 0.33333333 0.33333333 0.26027397], mean accuary is 0.27498088803487675\n",
    "Scores: recall is [0.17241379 0.06896552 0.34482759 0.28571429 0.67857143], mean accuary is 0.31009852216748773\n",
    "Scores: f1 is [0.2173913  0.0952381  0.33898305 0.30769231 0.37623762], mean accuary is 0.26710847637761254\n",
    "Scores: roc_auc is [0.56783493 0.60655738 0.65008479 0.71544715 0.69818501], mean accuary is 0.6476218543781174\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C:  100\n",
      "Best score:  0.26710847637761254\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nBest penalty:  rbf\\nBest C:  10\\nScores:  [0.41666667 0.3902439  0.45454545 0.30769231 0.38596491]\\nMean Score:  0.391022648724831\\n'"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = SVC(kernel='rbf', max_iter=10000)\n",
    "param_grid = {'C':[1, 10, 100], }\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# print(\"Best penalty: \", grid_search.best_params_['kernel'])\n",
    "print(\"Best C: \", grid_search.best_params_['C'])\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "'''\n",
    "Best penalty:  rbf\n",
    "Best C:  100\n",
    "\n",
    "Scores:  [0.36065574 0.44067797 0.45901639 0.31111111 0.40740741]\n",
    "Mean Score:  0.39577372315355086\n",
    "Scores:  [0.74274194 0.71833931 0.72649573 0.70439633 0.69226137]\n",
    "Mean Score:  0.7168469323092028\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "-------------------------\n",
    "the content below is about random forest\n",
    "-------------------------\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.01734514, 0.16068573, 0.28216157, 0.01430664, 0.14128737,\n",
      "       0.28185511, 0.01490216, 0.14494061, 0.31622529, 0.02696857,\n",
      "       0.15756593, 0.31592894, 0.01781864, 0.17361803, 0.32370877,\n",
      "       0.01726084, 0.15608826, 0.30447612, 0.01571198, 0.1448916 ,\n",
      "       0.30634384, 0.01821537, 0.17364182, 0.34628668, 0.01830478,\n",
      "       0.17421179, 0.34690442, 0.01754675, 0.18497791, 0.3400641 ,\n",
      "       0.01735907, 0.17546306, 0.33989615, 0.01592422, 0.16006503,\n",
      "       0.31505375, 0.01705775, 0.16530571, 0.33389678, 0.01631627,\n",
      "       0.16559253, 0.35043759, 0.01865635, 0.16335206, 0.32897782,\n",
      "       0.0180346 , 0.16445827, 0.32268572, 0.01877532, 0.16420498,\n",
      "       0.32088132, 0.01587014, 0.15290375, 0.33746881, 0.01755424,\n",
      "       0.16485071, 0.33535342, 0.01709714, 0.16423483, 0.32784171,\n",
      "       0.01677923, 0.16552539, 0.32664032, 0.01699338, 0.16298189,\n",
      "       0.32894125, 0.0170351 , 0.16457834, 0.33428617, 0.01688228,\n",
      "       0.16547685, 0.3286665 , 0.01673207, 0.16223483, 0.32399354,\n",
      "       0.01658702, 0.16390767, 0.32338991, 0.01726446, 0.16212893,\n",
      "       0.32364974, 0.01803617, 0.17279558, 0.34731431, 0.01811237,\n",
      "       0.17474904, 0.34821806, 0.01814198, 0.17307901, 0.35438027,\n",
      "       0.01822925, 0.17064672, 0.34407439, 0.0180162 , 0.17088199,\n",
      "       0.3445035 , 0.017273  , 0.17230597, 0.34095025, 0.0178596 ,\n",
      "       0.17094078, 0.34246249, 0.01732082, 0.16913424, 0.34120431,\n",
      "       0.01743965, 0.17020555, 0.33976541, 0.01796203, 0.17870374,\n",
      "       0.36355028, 0.0182632 , 0.1795835 , 0.3568357 , 0.01848712,\n",
      "       0.17907476, 0.35871129, 0.01861358, 0.17700124, 0.35349607,\n",
      "       0.01792197, 0.17659931, 0.35971427, 0.01799364, 0.18006248,\n",
      "       0.37351046, 0.023806  , 0.184131  , 0.35334234, 0.01775713,\n",
      "       0.18014755, 0.3531693 , 0.01826024, 0.17963328, 0.36627669,\n",
      "       0.01866851, 0.1847085 , 0.37007904, 0.01918087, 0.18563356,\n",
      "       0.37213655, 0.01909614, 0.18846741, 0.37404618, 0.01837168,\n",
      "       0.18312845, 0.35845785, 0.02012739, 0.18018675, 0.36700993,\n",
      "       0.01922598, 0.18210049, 0.36192303, 0.01821795, 0.17648001,\n",
      "       0.35367489, 0.01786766, 0.17587595, 0.35443749, 0.01817698,\n",
      "       0.17518392, 0.36101174]), 'std_fit_time': array([0.00201522, 0.03500048, 0.00228697, 0.00026993, 0.00217572,\n",
      "       0.00102473, 0.00036879, 0.00374498, 0.02396421, 0.01277055,\n",
      "       0.01335745, 0.01744638, 0.0004523 , 0.0099993 , 0.02086356,\n",
      "       0.00052076, 0.00403736, 0.01184706, 0.00111103, 0.00232228,\n",
      "       0.02641368, 0.00025015, 0.00456126, 0.0068891 , 0.00107808,\n",
      "       0.00143125, 0.0305978 , 0.00110484, 0.00428723, 0.02694208,\n",
      "       0.00044093, 0.01789477, 0.02917702, 0.00059919, 0.00207904,\n",
      "       0.01131417, 0.00084116, 0.00494864, 0.02190546, 0.0010039 ,\n",
      "       0.00492408, 0.01977823, 0.00083588, 0.00439248, 0.01538444,\n",
      "       0.00154071, 0.00747795, 0.00426476, 0.00104181, 0.00706024,\n",
      "       0.01506407, 0.00053074, 0.00203699, 0.02171361, 0.00082123,\n",
      "       0.00163397, 0.00812245, 0.00080862, 0.00185851, 0.00305591,\n",
      "       0.00025465, 0.00112763, 0.00232591, 0.00056867, 0.00128063,\n",
      "       0.00464781, 0.00062098, 0.00342878, 0.01714579, 0.00062595,\n",
      "       0.00174   , 0.00119549, 0.00093267, 0.00155053, 0.00287108,\n",
      "       0.00075441, 0.00253379, 0.00251487, 0.00099636, 0.00298206,\n",
      "       0.005958  , 0.00076538, 0.00093536, 0.00382728, 0.00066319,\n",
      "       0.0012305 , 0.00727368, 0.00170661, 0.00270905, 0.02039302,\n",
      "       0.00057573, 0.00156302, 0.00335457, 0.00052983, 0.00033217,\n",
      "       0.00367974, 0.0002584 , 0.00391307, 0.00435972, 0.00074061,\n",
      "       0.00280755, 0.00886086, 0.00058005, 0.0033431 , 0.00177015,\n",
      "       0.00063586, 0.0042048 , 0.00796412, 0.00034122, 0.00244454,\n",
      "       0.00853743, 0.0004631 , 0.00213233, 0.00280074, 0.00093314,\n",
      "       0.00224338, 0.00087738, 0.0011511 , 0.0018476 , 0.00422094,\n",
      "       0.00043659, 0.00267348, 0.01227144, 0.00085459, 0.01556433,\n",
      "       0.02319245, 0.00649053, 0.00894032, 0.00422962, 0.00030329,\n",
      "       0.00386159, 0.003389  , 0.0008047 , 0.00314745, 0.01429323,\n",
      "       0.0005734 , 0.0037717 , 0.0075444 , 0.00059114, 0.00363217,\n",
      "       0.00421757, 0.00081388, 0.00537436, 0.00350259, 0.0004562 ,\n",
      "       0.00692476, 0.00555043, 0.00179862, 0.00255804, 0.01001343,\n",
      "       0.00138262, 0.00611639, 0.00356014, 0.00131936, 0.00375216,\n",
      "       0.0045615 , 0.00061968, 0.00534939, 0.00455113, 0.00054416,\n",
      "       0.00313774, 0.0060058 ]), 'mean_score_time': array([0.00180717, 0.00949903, 0.01562057, 0.00160103, 0.00790224,\n",
      "       0.0165451 , 0.00169587, 0.00837502, 0.01723585, 0.00479102,\n",
      "       0.00860176, 0.01668277, 0.00192761, 0.01022019, 0.01785779,\n",
      "       0.00194864, 0.00898013, 0.01577139, 0.00180273, 0.00806475,\n",
      "       0.01759558, 0.00203333, 0.01054926, 0.02034831, 0.00202541,\n",
      "       0.01017962, 0.01925521, 0.00194674, 0.00952406, 0.01651573,\n",
      "       0.00188355, 0.00999422, 0.01624312, 0.00156603, 0.00883427,\n",
      "       0.01695104, 0.00165982, 0.00965219, 0.01818137, 0.00161667,\n",
      "       0.0094923 , 0.01839142, 0.00185776, 0.00863123, 0.017838  ,\n",
      "       0.00178561, 0.00885773, 0.016049  , 0.00186253, 0.00847368,\n",
      "       0.01680098, 0.0015728 , 0.00809412, 0.01716452, 0.00164781,\n",
      "       0.0082737 , 0.01590877, 0.00163927, 0.0088717 , 0.01522799,\n",
      "       0.00158377, 0.00855904, 0.01621661, 0.00163541, 0.00823884,\n",
      "       0.01629038, 0.00176272, 0.00870399, 0.01611586, 0.00161753,\n",
      "       0.00846591, 0.0158709 , 0.0015801 , 0.00828176, 0.01590118,\n",
      "       0.00181565, 0.00826759, 0.01617165, 0.00164995, 0.00830383,\n",
      "       0.01544857, 0.00173063, 0.00864172, 0.01636715, 0.00159721,\n",
      "       0.00832438, 0.01595941, 0.0015626 , 0.00817213, 0.01709065,\n",
      "       0.00173507, 0.00832567, 0.0157629 , 0.00172305, 0.00825448,\n",
      "       0.01568813, 0.0015882 , 0.008744  , 0.01589866, 0.00182157,\n",
      "       0.00887723, 0.01591592, 0.00160713, 0.00823603, 0.01652088,\n",
      "       0.00157361, 0.00856047, 0.01593137, 0.00152636, 0.00847378,\n",
      "       0.01651831, 0.00163336, 0.00896707, 0.01597505, 0.00170064,\n",
      "       0.00910506, 0.01615887, 0.00170741, 0.00827417, 0.01643343,\n",
      "       0.00157528, 0.00874867, 0.0158649 , 0.00157824, 0.0086    ,\n",
      "       0.01653171, 0.00190921, 0.00852885, 0.01676936, 0.00162368,\n",
      "       0.00864725, 0.01625738, 0.00166707, 0.00856857, 0.01620164,\n",
      "       0.00170674, 0.00867605, 0.01645212, 0.0016377 , 0.00850115,\n",
      "       0.01594157, 0.00158463, 0.00889354, 0.01621094, 0.00155692,\n",
      "       0.00864711, 0.01612182, 0.00179486, 0.00837855, 0.0166635 ,\n",
      "       0.00165458, 0.00834155, 0.01823258, 0.00157104, 0.00875144,\n",
      "       0.01600413, 0.00155821, 0.00900612, 0.01647754, 0.00161247,\n",
      "       0.00859871, 0.0167016 ]), 'std_score_time': array([2.22488069e-04, 2.72453039e-03, 5.91524281e-04, 8.91003628e-05,\n",
      "       1.10129524e-04, 1.50851472e-03, 3.22193296e-04, 7.93019513e-04,\n",
      "       1.63632523e-03, 5.02691640e-03, 6.18711025e-04, 1.32387743e-03,\n",
      "       1.33822375e-04, 1.09654418e-03, 1.15269459e-03, 6.44773768e-05,\n",
      "       7.59676521e-04, 8.82200098e-04, 2.09021687e-04, 1.02378170e-04,\n",
      "       1.96781045e-03, 6.39914045e-05, 2.13379082e-04, 1.50677494e-03,\n",
      "       7.35259705e-05, 3.54644109e-04, 2.38223913e-03, 1.37492123e-04,\n",
      "       6.10465143e-04, 1.08658963e-03, 2.04821592e-04, 2.02632228e-03,\n",
      "       1.26047067e-03, 4.95049297e-05, 5.77645296e-04, 2.29199051e-03,\n",
      "       1.11951413e-04, 2.06033632e-03, 1.58446103e-03, 5.75029631e-05,\n",
      "       8.32016945e-04, 2.58087763e-03, 1.66480645e-04, 5.47650414e-04,\n",
      "       1.82651730e-03, 1.96575597e-04, 6.06735459e-04, 4.01522416e-04,\n",
      "       3.02480816e-04, 4.03381673e-04, 2.18961011e-03, 7.35245789e-05,\n",
      "       4.81857182e-04, 1.46615368e-03, 1.36840185e-04, 3.24976981e-04,\n",
      "       4.98179632e-04, 1.44627202e-04, 7.08844484e-04, 4.86838862e-04,\n",
      "       8.11910169e-05, 4.48493584e-04, 1.08914096e-03, 9.69891468e-05,\n",
      "       1.96709482e-04, 1.49221870e-03, 3.03467821e-04, 9.78373830e-04,\n",
      "       1.02059220e-03, 9.86673448e-05, 3.31600034e-04, 8.64008610e-04,\n",
      "       8.57427730e-05, 3.73970053e-04, 7.59320956e-04, 3.42900049e-04,\n",
      "       8.90413948e-05, 5.59480932e-04, 6.39405737e-05, 3.39778962e-04,\n",
      "       2.18751716e-04, 2.46656086e-04, 6.36842972e-04, 1.12234623e-03,\n",
      "       9.40432890e-05, 2.79242045e-04, 2.81965815e-04, 3.82936162e-05,\n",
      "       1.80103333e-04, 1.30384760e-03, 2.15312048e-04, 3.10060721e-04,\n",
      "       2.71583465e-04, 1.42865935e-04, 2.45332574e-04, 2.65358032e-04,\n",
      "       8.39319550e-05, 1.17049472e-03, 7.08980842e-04, 2.56396737e-04,\n",
      "       5.68585662e-04, 3.84640344e-04, 6.86571660e-05, 2.32735840e-04,\n",
      "       1.20548275e-03, 2.05369064e-05, 8.32755195e-04, 6.10358492e-04,\n",
      "       3.60114670e-05, 2.45702884e-04, 6.27968747e-04, 1.19881300e-04,\n",
      "       1.02299259e-03, 9.08329297e-04, 3.29813858e-04, 1.10490612e-03,\n",
      "       1.10042426e-03, 1.05984457e-04, 1.85863063e-04, 5.65551694e-04,\n",
      "       4.73041688e-05, 2.79793994e-04, 3.65112204e-04, 5.66103516e-05,\n",
      "       3.52115394e-04, 7.96756324e-04, 2.02487842e-04, 4.77733071e-04,\n",
      "       9.69047842e-04, 6.72687617e-05, 3.82305018e-04, 9.29855990e-04,\n",
      "       5.34860399e-05, 2.67347563e-04, 7.35819833e-04, 1.84535278e-04,\n",
      "       3.19336318e-04, 6.94700771e-04, 7.03303288e-05, 2.08637405e-04,\n",
      "       5.56726188e-04, 1.59790971e-05, 3.68412652e-04, 3.55922530e-04,\n",
      "       4.49527214e-05, 4.69072994e-04, 2.17297649e-04, 2.19664103e-04,\n",
      "       4.09151218e-04, 1.35770526e-03, 5.45967927e-05, 2.07871743e-04,\n",
      "       2.66909693e-03, 1.04889175e-04, 6.94455648e-04, 5.05424859e-04,\n",
      "       7.50218980e-05, 9.07151903e-04, 1.06588690e-03, 1.27277243e-04,\n",
      "       2.67303768e-04, 6.42203580e-04]), 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   2, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200, 10, 100, 200, 10, 100, 200,\n",
      "                   10, 100, 200, 10, 100, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}], 'split0_test_score': array([0.06666667, 0.        , 0.        , 0.06666667, 0.        ,\n",
      "       0.        , 0.06666667, 0.        , 0.        , 0.06666667,\n",
      "       0.        , 0.        , 0.06666667, 0.        , 0.        ,\n",
      "       0.06666667, 0.        , 0.        , 0.06451613, 0.        ,\n",
      "       0.        , 0.06451613, 0.        , 0.        , 0.06451613,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.0625    , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.06666667, 0.        ,\n",
      "       0.        , 0.06666667, 0.        , 0.        , 0.06666667,\n",
      "       0.        , 0.05714286, 0.        , 0.        , 0.06060606,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.05882353, 0.06666667, 0.        , 0.05882353, 0.06666667,\n",
      "       0.        , 0.05882353, 0.06666667, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.05882353, 0.        , 0.        , 0.05405405,\n",
      "       0.        , 0.        , 0.11428571, 0.06451613, 0.        ,\n",
      "       0.11428571, 0.06451613, 0.        , 0.11428571, 0.06451613,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.10810811, 0.        , 0.        , 0.05714286, 0.0625    ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.06666667, 0.        , 0.        , 0.06666667, 0.        ,\n",
      "       0.        , 0.06666667, 0.        , 0.11428571, 0.        ,\n",
      "       0.        , 0.11428571, 0.        , 0.        , 0.11428571,\n",
      "       0.        , 0.        ]), 'split1_test_score': array([0.        , 0.06666667, 0.06666667, 0.        , 0.06666667,\n",
      "       0.06666667, 0.        , 0.06666667, 0.06666667, 0.        ,\n",
      "       0.06666667, 0.        , 0.        , 0.06666667, 0.        ,\n",
      "       0.        , 0.06666667, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.06666667, 0.06666667,\n",
      "       0.        , 0.06666667, 0.06666667, 0.        , 0.06666667,\n",
      "       0.06666667, 0.        , 0.06666667, 0.06666667, 0.        ,\n",
      "       0.06666667, 0.06666667, 0.        , 0.06666667, 0.06666667,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.06666667, 0.06666667, 0.06451613, 0.06666667, 0.06666667,\n",
      "       0.06451613, 0.06666667, 0.06666667, 0.        , 0.06666667,\n",
      "       0.06666667, 0.        , 0.06666667, 0.06666667, 0.        ,\n",
      "       0.06666667, 0.06666667, 0.12121212, 0.        , 0.        ,\n",
      "       0.12121212, 0.        , 0.        , 0.12121212, 0.        ,\n",
      "       0.        , 0.        , 0.06666667, 0.06666667, 0.0625    ,\n",
      "       0.06666667, 0.06666667, 0.12903226, 0.06666667, 0.06666667,\n",
      "       0.06451613, 0.        , 0.06666667, 0.06451613, 0.        ,\n",
      "       0.06666667, 0.06451613, 0.        , 0.06666667, 0.0625    ,\n",
      "       0.        , 0.        , 0.0625    , 0.        , 0.        ,\n",
      "       0.0625    , 0.        , 0.        , 0.        , 0.06666667,\n",
      "       0.06666667, 0.05714286, 0.06666667, 0.06666667, 0.06060606,\n",
      "       0.06666667, 0.06666667, 0.06060606, 0.        , 0.06666667,\n",
      "       0.06060606, 0.        , 0.06666667, 0.06060606, 0.        ,\n",
      "       0.06666667, 0.06666667, 0.        , 0.        , 0.06666667,\n",
      "       0.        , 0.        , 0.06666667, 0.        , 0.        ,\n",
      "       0.        , 0.06666667, 0.06666667, 0.12121212, 0.06666667,\n",
      "       0.06666667, 0.06451613, 0.06666667, 0.06666667, 0.        ,\n",
      "       0.06666667, 0.06666667, 0.        , 0.06666667, 0.06666667,\n",
      "       0.        , 0.06666667, 0.06666667, 0.06666667, 0.        ,\n",
      "       0.        , 0.06666667, 0.        , 0.        , 0.06666667,\n",
      "       0.        , 0.        ]), 'split2_test_score': array([0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.06666667, 0.12903226,\n",
      "       0.12903226, 0.06666667, 0.12903226, 0.12903226, 0.06666667,\n",
      "       0.12903226, 0.12903226, 0.06666667, 0.12903226, 0.12903226,\n",
      "       0.06666667, 0.12903226, 0.12903226, 0.06666667, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.        , 0.12903226, 0.12903226, 0.        , 0.12903226,\n",
      "       0.12903226, 0.        , 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.06666667,\n",
      "       0.12903226, 0.12903226, 0.06666667, 0.12903226, 0.12903226,\n",
      "       0.06666667, 0.12903226, 0.06666667, 0.12903226, 0.12903226,\n",
      "       0.06666667, 0.12903226, 0.12903226, 0.06666667, 0.12903226,\n",
      "       0.12903226, 0.1875    , 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.18181818, 0.12903226, 0.12903226,\n",
      "       0.17142857, 0.06666667, 0.12903226, 0.17142857, 0.06666667,\n",
      "       0.12903226, 0.17142857, 0.06666667, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.12903226, 0.12903226,\n",
      "       0.12903226, 0.12903226, 0.12903226, 0.1875    , 0.12903226,\n",
      "       0.12903226, 0.1875    , 0.12903226, 0.1875    , 0.23529412,\n",
      "       0.18181818, 0.12903226, 0.17647059, 0.1875    , 0.1875    ,\n",
      "       0.17647059, 0.1875    , 0.1875    , 0.17647059, 0.1875    ,\n",
      "       0.1875    , 0.1875    , 0.12903226, 0.12903226, 0.1875    ,\n",
      "       0.12903226, 0.12903226, 0.1875    , 0.12903226, 0.12903226,\n",
      "       0.23529412, 0.12903226, 0.12903226, 0.24242424, 0.12903226,\n",
      "       0.12903226, 0.17647059, 0.125     , 0.1875    , 0.17647059,\n",
      "       0.12903226, 0.1875    , 0.17647059, 0.12903226, 0.1875    ,\n",
      "       0.17647059, 0.12903226, 0.1875    , 0.0625    , 0.12903226,\n",
      "       0.12903226, 0.0625    , 0.12903226, 0.12903226, 0.0625    ,\n",
      "       0.12903226, 0.12903226]), 'split3_test_score': array([0.06896552, 0.        , 0.        , 0.06896552, 0.        ,\n",
      "       0.        , 0.06896552, 0.        , 0.        , 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.        , 0.        , 0.        ,\n",
      "       0.13333333, 0.        , 0.        , 0.06896552, 0.        ,\n",
      "       0.        , 0.06896552, 0.        , 0.06896552, 0.06896552,\n",
      "       0.        , 0.06896552, 0.06896552, 0.        , 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
      "       0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
      "       0.        , 0.06896552, 0.06666667, 0.        , 0.06896552,\n",
      "       0.06666667, 0.        , 0.06896552, 0.1875    , 0.06896552,\n",
      "       0.06896552, 0.1875    , 0.06896552, 0.06896552, 0.1875    ,\n",
      "       0.06896552, 0.06896552, 0.0625    , 0.06896552, 0.06896552,\n",
      "       0.0625    , 0.06896552, 0.06896552, 0.0625    , 0.06896552,\n",
      "       0.06896552, 0.17142857, 0.06896552, 0.06896552, 0.        ,\n",
      "       0.06896552, 0.06896552, 0.125     , 0.06896552, 0.06896552,\n",
      "       0.06451613, 0.06896552, 0.06896552, 0.06451613, 0.06896552,\n",
      "       0.06896552, 0.06451613, 0.06896552, 0.06896552, 0.06060606,\n",
      "       0.06896552, 0.06896552, 0.06060606, 0.06896552, 0.06896552,\n",
      "       0.06060606, 0.06896552, 0.06896552, 0.12121212, 0.06896552,\n",
      "       0.06896552, 0.125     , 0.06896552, 0.06896552, 0.11111111,\n",
      "       0.06896552, 0.06896552, 0.11764706, 0.06666667, 0.06896552,\n",
      "       0.11764706, 0.06666667, 0.06896552, 0.11764706, 0.06666667,\n",
      "       0.06896552, 0.11111111, 0.06896552, 0.06896552, 0.11111111,\n",
      "       0.06896552, 0.06896552, 0.11111111, 0.06896552, 0.06896552,\n",
      "       0.12121212, 0.12903226, 0.06896552, 0.17647059, 0.19354839,\n",
      "       0.06896552, 0.06666667, 0.06896552, 0.06896552, 0.125     ,\n",
      "       0.06896552, 0.06896552, 0.125     , 0.06896552, 0.06896552,\n",
      "       0.125     , 0.06896552, 0.06896552, 0.06451613, 0.06666667,\n",
      "       0.06896552, 0.06451613, 0.06666667, 0.06896552, 0.06451613,\n",
      "       0.06666667, 0.06896552]), 'split4_test_score': array([0.14634146, 0.31111111, 0.28571429, 0.15      , 0.31111111,\n",
      "       0.29166667, 0.15      , 0.31111111, 0.32653061, 0.19047619,\n",
      "       0.31818182, 0.32653061, 0.19047619, 0.31818182, 0.32653061,\n",
      "       0.19047619, 0.31818182, 0.32653061, 0.3255814 , 0.26666667,\n",
      "       0.32653061, 0.3255814 , 0.26666667, 0.32653061, 0.3255814 ,\n",
      "       0.26666667, 0.32653061, 0.21276596, 0.32      , 0.31372549,\n",
      "       0.22222222, 0.32      , 0.30769231, 0.29787234, 0.31372549,\n",
      "       0.30769231, 0.22727273, 0.31372549, 0.30769231, 0.22727273,\n",
      "       0.31372549, 0.30769231, 0.22727273, 0.31372549, 0.30769231,\n",
      "       0.35294118, 0.32      , 0.32      , 0.35294118, 0.32      ,\n",
      "       0.32      , 0.35294118, 0.32      , 0.32      , 0.23076923,\n",
      "       0.35294118, 0.33333333, 0.19607843, 0.34615385, 0.33333333,\n",
      "       0.17391304, 0.31372549, 0.36363636, 0.19047619, 0.36      ,\n",
      "       0.33333333, 0.19047619, 0.36      , 0.33333333, 0.19047619,\n",
      "       0.36      , 0.33333333, 0.32      , 0.36363636, 0.37037037,\n",
      "       0.32      , 0.36363636, 0.37037037, 0.32      , 0.36363636,\n",
      "       0.37037037, 0.29090909, 0.36363636, 0.38596491, 0.30188679,\n",
      "       0.38596491, 0.4137931 , 0.30769231, 0.42105263, 0.40677966,\n",
      "       0.2962963 , 0.39285714, 0.4137931 , 0.2962963 , 0.39285714,\n",
      "       0.4137931 , 0.2962963 , 0.39285714, 0.4137931 , 0.33898305,\n",
      "       0.37037037, 0.4       , 0.33898305, 0.37037037, 0.4       ,\n",
      "       0.33898305, 0.37037037, 0.4       , 0.36065574, 0.37931034,\n",
      "       0.4137931 , 0.40677966, 0.37931034, 0.4137931 , 0.37037037,\n",
      "       0.39285714, 0.42105263, 0.30188679, 0.38596491, 0.4137931 ,\n",
      "       0.30188679, 0.38596491, 0.4137931 , 0.30188679, 0.38596491,\n",
      "       0.4137931 , 0.375     , 0.4       , 0.36363636, 0.375     ,\n",
      "       0.4       , 0.36363636, 0.375     , 0.4       , 0.36363636,\n",
      "       0.36065574, 0.38596491, 0.4       , 0.35483871, 0.42622951,\n",
      "       0.41269841, 0.36363636, 0.40677966, 0.4       , 0.39285714,\n",
      "       0.40677966, 0.40677966, 0.39285714, 0.40677966, 0.40677966,\n",
      "       0.39285714, 0.40677966, 0.40677966, 0.37931034, 0.43636364,\n",
      "       0.39285714, 0.37931034, 0.43636364, 0.39285714, 0.37931034,\n",
      "       0.43636364, 0.39285714]), 'mean_test_score': array([0.08220118, 0.10136201, 0.09628264, 0.08293289, 0.10136201,\n",
      "       0.09747312, 0.08293289, 0.10136201, 0.10444591, 0.09102813,\n",
      "       0.11656925, 0.10490568, 0.09102813, 0.11656925, 0.10490568,\n",
      "       0.09102813, 0.11656925, 0.10490568, 0.10514594, 0.09293289,\n",
      "       0.10490568, 0.10514594, 0.09293289, 0.10490568, 0.10514594,\n",
      "       0.09293289, 0.10490568, 0.05588652, 0.10313978, 0.10188488,\n",
      "       0.08444444, 0.10313978, 0.10067825, 0.0867009 , 0.10188488,\n",
      "       0.10067825, 0.0850541 , 0.10188488, 0.11447135, 0.0850541 ,\n",
      "       0.10188488, 0.11447135, 0.0850541 , 0.10188488, 0.11447135,\n",
      "       0.08438134, 0.10359956, 0.10359956, 0.08438134, 0.10359956,\n",
      "       0.10359956, 0.08438134, 0.10359956, 0.10359956, 0.0857534 ,\n",
      "       0.10972802, 0.11959956, 0.1037587 , 0.10837055, 0.11959956,\n",
      "       0.08682562, 0.10188488, 0.12566016, 0.10140169, 0.11245977,\n",
      "       0.11959956, 0.10140169, 0.11245977, 0.11959956, 0.10140169,\n",
      "       0.11245977, 0.11959956, 0.11407576, 0.12566016, 0.11367363,\n",
      "       0.11407576, 0.12566016, 0.11367363, 0.11407576, 0.12566016,\n",
      "       0.11367363, 0.1413961 , 0.12566016, 0.13012587, 0.11080502,\n",
      "       0.13012587, 0.13569151, 0.14870855, 0.13714341, 0.13428882,\n",
      "       0.13111613, 0.1190312 , 0.13569151, 0.13111613, 0.1190312 ,\n",
      "       0.13569151, 0.13111613, 0.1190312 , 0.13569151, 0.11822427,\n",
      "       0.11367363, 0.11959956, 0.11822427, 0.11367363, 0.11959956,\n",
      "       0.11822427, 0.11367363, 0.11959956, 0.13387357, 0.12879496,\n",
      "       0.13569151, 0.16704921, 0.12879496, 0.14738506, 0.16628714,\n",
      "       0.1420615 , 0.13714341, 0.15417924, 0.14092954, 0.14738506,\n",
      "       0.15417924, 0.14092954, 0.14738506, 0.15417924, 0.14092954,\n",
      "       0.14738506, 0.14805556, 0.11959956, 0.11232683, 0.14805556,\n",
      "       0.11959956, 0.11232683, 0.14805556, 0.11959956, 0.11232683,\n",
      "       0.16505402, 0.14213922, 0.13293289, 0.1904177 , 0.17559536,\n",
      "       0.13547257, 0.13425795, 0.13348237, 0.14462644, 0.13886555,\n",
      "       0.14762215, 0.14598237, 0.13886555, 0.14762215, 0.14598237,\n",
      "       0.13886555, 0.14762215, 0.14598237, 0.13745577, 0.12641251,\n",
      "       0.11817098, 0.13745577, 0.12641251, 0.11817098, 0.13745577,\n",
      "       0.12641251, 0.11817098]), 'std_test_score': array([0.0519243 , 0.11533656, 0.10618351, 0.05284069, 0.11533656,\n",
      "       0.10831267, 0.05284069, 0.11533656, 0.12097212, 0.06434375,\n",
      "       0.10876371, 0.12083195, 0.06434375, 0.10876371, 0.12083195,\n",
      "       0.06434375, 0.10876371, 0.12083195, 0.11321477, 0.09933184,\n",
      "       0.12083195, 0.11321477, 0.09933184, 0.12083195, 0.11321477,\n",
      "       0.09933184, 0.12083195, 0.08258   , 0.11857883, 0.11628827,\n",
      "       0.0847946 , 0.11857883, 0.1140945 , 0.10985753, 0.11628827,\n",
      "       0.1140945 , 0.08589233, 0.11628827, 0.10488672, 0.08589233,\n",
      "       0.11628827, 0.10488672, 0.08589233, 0.11628827, 0.10488672,\n",
      "       0.13691068, 0.11844089, 0.11844089, 0.13691068, 0.11844089,\n",
      "       0.11844089, 0.13691068, 0.11844089, 0.11844089, 0.08705375,\n",
      "       0.13073641, 0.11440354, 0.05249717, 0.12821495, 0.11440354,\n",
      "       0.05967982, 0.11628827, 0.12580066, 0.08564489, 0.12649833,\n",
      "       0.11440354, 0.08564489, 0.12649833, 0.11440354, 0.08564489,\n",
      "       0.12649833, 0.11440354, 0.10988783, 0.12580066, 0.13709216,\n",
      "       0.10988783, 0.12580066, 0.13709216, 0.10988783, 0.12580066,\n",
      "       0.13709216, 0.10244327, 0.12580066, 0.13427972, 0.10389951,\n",
      "       0.13427972, 0.1449233 , 0.09943397, 0.14771171, 0.1422338 ,\n",
      "       0.09274365, 0.13938417, 0.1449233 , 0.09274365, 0.13938417,\n",
      "       0.1449233 , 0.09274365, 0.13938417, 0.1449233 , 0.11768881,\n",
      "       0.13709216, 0.14824662, 0.11768881, 0.13709216, 0.14824662,\n",
      "       0.11768881, 0.13709216, 0.14824662, 0.13439533, 0.13174646,\n",
      "       0.1449233 , 0.12918921, 0.13174646, 0.14626681, 0.12101329,\n",
      "       0.13833866, 0.14771171, 0.08245782, 0.13669401, 0.14626681,\n",
      "       0.08245782, 0.13669401, 0.14626681, 0.08245782, 0.13669401,\n",
      "       0.14626681, 0.12881703, 0.14824662, 0.13457369, 0.12881703,\n",
      "       0.14824662, 0.13457369, 0.12881703, 0.14824662, 0.13457369,\n",
      "       0.12296461, 0.13091541, 0.13963828, 0.10245493, 0.13413719,\n",
      "       0.14450322, 0.12794848, 0.14227274, 0.14126069, 0.14469651,\n",
      "       0.13175936, 0.14371664, 0.14469651, 0.13175936, 0.14371664,\n",
      "       0.14469651, 0.13175936, 0.14371664, 0.12245827, 0.16223833,\n",
      "       0.14554751, 0.12245827, 0.16223833, 0.14554751, 0.12245827,\n",
      "       0.16223833, 0.14554751]), 'rank_test_score': array([161, 136, 142, 159, 136, 141, 159, 136, 117, 146,  84, 111, 146,\n",
      "        84, 111, 146,  84, 111, 108, 143, 111, 108, 143, 111, 108, 143,\n",
      "       111, 162, 125, 127, 155, 125, 139, 150, 127, 139, 152, 127,  87,\n",
      "       152, 127,  87, 152, 127,  87, 156, 119, 119, 156, 119, 119, 156,\n",
      "       119, 119, 151, 106,  64, 118, 107,  64, 149, 127,  59, 133,  99,\n",
      "        64, 133,  99,  64, 133,  99,  64,  90,  59,  93,  90,  59,  93,\n",
      "        90,  59,  93,  26,  59,  52, 105,  52,  38,   9,  36,  44,  49,\n",
      "        75,  38,  49,  75,  38,  49,  75,  38,  78,  93,  64,  78,  93,\n",
      "        64,  78,  93,  64,  46,  54,  38,   3,  54,  16,   4,  25,  36,\n",
      "         6,  27,  16,   6,  27,  16,   6,  27,  16,  10,  64, 102,  10,\n",
      "        64, 102,  10,  64, 102,   5,  24,  48,   1,   2,  43,  45,  47,\n",
      "        23,  30,  13,  20,  30,  13,  20,  30,  13,  20,  33,  56,  81,\n",
      "        33,  56,  81,  33,  56,  81], dtype=int32)}\n",
      "{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {'n_estimators':[10, 100, 200], 'max_depth':[4, 5, 6, 7, 8, 9], 'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=32)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.cv_results_)\n",
    "print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: accuracy is [0.79470199 0.80794702 0.81456954 0.81456954 0.76666667], mean accuary is 0.799690949227373\n",
      "Scores: precision is [0.         0.5        0.6        0.5        0.37037037], mean precision is 0.3940740740740741\n",
      "Scores: recall is [0.         0.03448276 0.10344828 0.03571429 0.35714286], mean recall is 0.1061576354679803\n",
      "Scores: f1 is [0.         0.06451613 0.17647059 0.06666667 0.36363636], mean f1 is 0.13425794951411651\n",
      "Scores: roc_auc is [0.49166196 0.40276993 0.65220464 0.60307782 0.70418618], mean roc_auc is 0.5707801033937822\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nScores:  [0.37209302 0.31578947 0.34042553 0.1875     0.37837838]\\nMean Score:  0.31883728144665924\\nScores:  [0.77956989 0.72371565 0.79839115 0.77788714 0.75127974]\\nMean Score:  0.7661687138135271\\n\\n'"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth=9, min_samples_leaf=1, min_samples_split=4, random_state=32)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "scores = cross_validate(rf_model, X, y, cv=5, scoring=scoring)\n",
    "print(\"Scores: accuracy is {}, mean accuary is {}\".format(scores['test_accuracy'], scores['test_accuracy'].mean()))\n",
    "print(\"Scores: precision is {}, mean precision is {}\".format(scores['test_precision'], scores['test_precision'].mean()))\n",
    "print(\"Scores: recall is {}, mean recall is {}\".format(scores['test_recall'], scores['test_recall'].mean()))\n",
    "print(\"Scores: f1 is {}, mean f1 is {}\".format(scores['test_f1'], scores['test_f1'].mean()))\n",
    "print(\"Scores: roc_auc is {}, mean roc_auc is {}\".format(scores['test_roc_auc'], scores['test_roc_auc'].mean()))\n",
    "\n",
    "# print(\"Score with L1 penalty: accuracy:{} precision:{} recall:{} f1:{} roc_auc:{}\".format(accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)))\n",
    "'''\n",
    "Scores:  [0.37209302 0.31578947 0.34042553 0.1875     0.37837838]\n",
    "Mean Score:  0.31883728144665924\n",
    "Scores:  [0.77956989 0.72371565 0.79839115 0.77788714 0.75127974]\n",
    "Mean Score:  0.7661687138135271\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}